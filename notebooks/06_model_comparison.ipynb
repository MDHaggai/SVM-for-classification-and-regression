{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Comparison for Heart Disease Diagnosis\n",
    "\n",
    "In this notebook, we will conduct a thorough comparison of Support Vector Machines (SVM) with other machine learning models for heart disease diagnosis. This analysis is crucial for selecting the most appropriate model for clinical deployment in cardiovascular medicine.\n",
    "\n",
    "## Medical Context\n",
    "\n",
    "Heart disease remains the leading cause of death globally. Accurate early diagnosis is essential for:\n",
    "- **Early intervention**: Preventing progression to severe cardiovascular events\n",
    "- **Treatment planning**: Selecting appropriate therapeutic interventions\n",
    "- **Risk stratification**: Identifying high-risk patients requiring intensive monitoring\n",
    "- **Healthcare resource allocation**: Optimizing clinical workflows and resources\n",
    "\n",
    "## Model Selection Criteria\n",
    "\n",
    "For medical diagnosis, we prioritize:\n",
    "1. **Sensitivity (Recall)**: Ability to correctly identify patients with heart disease (minimize false negatives)\n",
    "2. **Specificity**: Ability to correctly identify healthy patients (minimize false positives)\n",
    "3. **Interpretability**: Understanding why the model makes specific predictions\n",
    "4. **Robustness**: Consistent performance across different patient populations\n",
    "5. **Clinical applicability**: Practical implementation in healthcare settings\n",
    "\n",
    "## Models Under Evaluation\n",
    "\n",
    "1. **Support Vector Machine (SVM)**: Multiple kernel configurations\n",
    "2. **Logistic Regression**: Linear probabilistic model with medical interpretability\n",
    "3. **Random Forest**: Ensemble method with feature importance insights\n",
    "4. **Naive Bayes**: Probabilistic model with strong independence assumptions\n",
    "5. **K-Nearest Neighbors (KNN)**: Instance-based learning for pattern recognition\n",
    "6. **Decision Tree**: Interpretable rule-based model for clinical decision support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for comprehensive medical model comparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style for medical presentations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "fig_size = (12, 8)\n",
    "\n",
    "print(\"ðŸ“Š Libraries loaded successfully for comprehensive heart disease model comparison\")\n",
    "print(\"ðŸ¥ Focus: Medical diagnosis and clinical decision support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare heart disease dataset for comprehensive model comparison\n",
    "from sklearn.datasets import load_iris  # Placeholder - will load actual heart disease data\n",
    "\n",
    "# Load heart disease dataset\n",
    "print(\"ðŸ«€ Loading Heart Disease Dataset for Model Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For demonstration, we'll create a realistic heart disease dataset\n",
    "# In practice, this would load from your actual medical database\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate realistic heart disease features with medical correlations\n",
    "data = {\n",
    "    'age': np.random.normal(54, 12, n_samples),\n",
    "    'sex': np.random.binomial(1, 0.68, n_samples),  # Male predominance\n",
    "    'cp': np.random.choice([0, 1, 2, 3], n_samples, p=[0.47, 0.16, 0.29, 0.08]),\n",
    "    'trestbps': np.random.normal(131, 17, n_samples),\n",
    "    'chol': np.random.normal(246, 51, n_samples),\n",
    "    'fbs': np.random.binomial(1, 0.15, n_samples),\n",
    "    'restecg': np.random.choice([0, 1, 2], n_samples, p=[0.48, 0.48, 0.04]),\n",
    "    'thalach': np.random.normal(150, 22, n_samples),\n",
    "    'exang': np.random.binomial(1, 0.33, n_samples),\n",
    "    'oldpeak': np.random.exponential(1.0, n_samples),\n",
    "    'slope': np.random.choice([0, 1, 2], n_samples, p=[0.21, 0.14, 0.65]),\n",
    "    'ca': np.random.choice([0, 1, 2, 3], n_samples, p=[0.59, 0.21, 0.13, 0.07]),\n",
    "    'thal': np.random.choice([0, 1, 2, 3], n_samples, p=[0.02, 0.18, 0.17, 0.63])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_heart = pd.DataFrame(data)\n",
    "\n",
    "# Clip values to realistic medical ranges\n",
    "df_heart['age'] = np.clip(df_heart['age'], 29, 77)\n",
    "df_heart['trestbps'] = np.clip(df_heart['trestbps'], 94, 200)\n",
    "df_heart['chol'] = np.clip(df_heart['chol'], 126, 564)\n",
    "df_heart['thalach'] = np.clip(df_heart['thalach'], 71, 202)\n",
    "df_heart['oldpeak'] = np.clip(df_heart['oldpeak'], 0, 6.2)\n",
    "\n",
    "# Generate target based on medical risk factors with realistic correlations\n",
    "risk_score = (\n",
    "    0.15 * (df_heart['age'] - 29) / 48 +  # Age factor\n",
    "    0.20 * df_heart['sex'] +  # Male risk\n",
    "    0.25 * (df_heart['cp'] == 0) +  # Asymptomatic chest pain\n",
    "    0.15 * (df_heart['trestbps'] > 140) / 140 +  # Hypertension\n",
    "    0.10 * (df_heart['chol'] > 240) / 240 +  # High cholesterol\n",
    "    0.15 * df_heart['exang'] +  # Exercise angina\n",
    "    0.20 * (df_heart['oldpeak'] > 2) +  # ST depression\n",
    "    0.25 * (df_heart['ca'] > 0) +  # Vessel blockage\n",
    "    0.30 * (df_heart['thal'] == 2)  # Fixed defect\n",
    ")\n",
    "\n",
    "# Convert to binary classification with medical threshold\n",
    "target_prob = 1 / (1 + np.exp(-5 * (risk_score - 0.5)))\n",
    "df_heart['target'] = np.random.binomial(1, target_prob, n_samples)\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_heart.drop('target', axis=1)\n",
    "y = df_heart['target']\n",
    "\n",
    "print(f\"ðŸ“ˆ Dataset Shape: {X.shape}\")\n",
    "print(f\"ðŸŽ¯ Target Distribution:\")\n",
    "print(f\"   - No Heart Disease (0): {(y == 0).sum()} patients ({(y == 0).mean():.1%})\")\n",
    "print(f\"   - Heart Disease (1): {(y == 1).sum()} patients ({(y == 1).mean():.1%})\")\n",
    "print(f\"\\nðŸ¥ Medical Features: {list(X.columns)}\")\n",
    "\n",
    "# Split data with stratification for medical validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Split:\")\n",
    "print(f\"   - Training: {X_train.shape[0]} patients\")\n",
    "print(f\"   - Testing: {X_test.shape[0]} patients\")\n",
    "print(f\"   - Feature scaling will be applied for SVM and KNN models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comprehensive set of models for medical diagnosis comparison\n",
    "print(\"ðŸ”¬ Initializing Medical Diagnosis Models\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define models with medical-appropriate configurations\n",
    "models = {\n",
    "    # Support Vector Machines with different kernels\n",
    "    'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'SVM (Polynomial)': SVC(kernel='poly', degree=3, probability=True, random_state=42),\n",
    "    \n",
    "    # Traditional statistical models\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \n",
    "    # Ensemble methods\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \n",
    "    # Probabilistic models\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    \n",
    "    # Instance-based learning\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    \n",
    "    # Tree-based interpretable model\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "}\n",
    "\n",
    "print(f\"ðŸ“‹ Models configured: {len(models)}\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"   âœ“ {model_name}\")\n",
    "\n",
    "# Initialize results storage for comprehensive medical evaluation\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Sensitivity (Recall)': [],  # Critical for medical diagnosis\n",
    "    'Specificity': [],  # Important for avoiding false alarms\n",
    "    'Precision (PPV)': [],  # Positive Predictive Value\n",
    "    'F1-Score': [],\n",
    "    'ROC-AUC': [],\n",
    "    'CV_Mean': [],  # Cross-validation mean\n",
    "    'CV_Std': []   # Cross-validation standard deviation\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation metrics configured for medical diagnosis:\")\n",
    "print(\"   â€¢ Sensitivity (Recall): Ability to detect heart disease\")\n",
    "print(\"   â€¢ Specificity: Ability to rule out heart disease\")\n",
    "print(\"   â€¢ Precision (PPV): Proportion of positive predictions that are correct\")\n",
    "print(\"   â€¢ ROC-AUC: Overall discriminative ability\")\n",
    "print(\"   â€¢ Cross-validation: Robustness assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model training and evaluation for heart disease diagnosis\n",
    "print(\"ðŸ¥ Training and Evaluating Models for Heart Disease Diagnosis\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Prepare data scaling for models that require it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Models that require scaling\n",
    "scaling_required = ['SVM (Linear)', 'SVM (RBF)', 'SVM (Polynomial)', \n",
    "                   'Logistic Regression', 'K-Nearest Neighbors']\n",
    "\n",
    "# Cross-validation setup for robust evaluation\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nðŸ”¬ Training {model_name}...\")\n",
    "    \n",
    "    # Select appropriate data (scaled or original)\n",
    "    if model_name in scaling_required:\n",
    "        X_train_model, X_test_model = X_train_scaled, X_test_scaled\n",
    "        print(f\"   ðŸ“Š Using scaled features for {model_name}\")\n",
    "    else:\n",
    "        X_train_model, X_test_model = X_train, X_test\n",
    "        print(f\"   ðŸ“Š Using original features for {model_name}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_model, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_model)\n",
    "    y_pred_proba = model.predict_proba(X_test_model)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate comprehensive medical metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred)  # True Positive Rate\n",
    "    precision = precision_score(y_test, y_pred)  # Positive Predictive Value\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate specificity (True Negative Rate)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Calculate ROC-AUC if probability predictions available\n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation for robustness assessment\n",
    "    cv_scores = cross_val_score(model, X_train_model, y_train, cv=cv_folds, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    # Store results\n",
    "    results['Model'].append(model_name)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Sensitivity (Recall)'].append(sensitivity)\n",
    "    results['Specificity'].append(specificity)\n",
    "    results['Precision (PPV)'].append(precision)\n",
    "    results['F1-Score'].append(f1)\n",
    "    results['ROC-AUC'].append(roc_auc)\n",
    "    results['CV_Mean'].append(cv_mean)\n",
    "    results['CV_Std'].append(cv_std)\n",
    "    \n",
    "    # Print medical performance summary\n",
    "    print(f\"   âœ… Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   ðŸŽ¯ Sensitivity: {sensitivity:.3f} (ability to detect heart disease)\")\n",
    "    print(f\"   ðŸ›¡ï¸  Specificity: {specificity:.3f} (ability to rule out heart disease)\")\n",
    "    print(f\"   ðŸ“Š ROC-AUC: {roc_auc:.3f}\")\n",
    "    print(f\"   ðŸ”„ CV Score: {cv_mean:.3f} Â± {cv_std:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… All models trained and evaluated successfully!\")\n",
    "print(\"ðŸ“ˆ Comprehensive medical performance metrics calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive model comparison results\n",
    "print(\"ðŸ“Š Comprehensive Model Comparison Results for Heart Disease Diagnosis\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by ROC-AUC (most important metric for medical diagnosis)\n",
    "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "# Display results with medical interpretation\n",
    "print(\"\\nðŸ† Model Rankings (sorted by ROC-AUC):\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Highlight top performers\n",
    "print(f\"\\nðŸ¥‡ Best Overall Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"   ROC-AUC: {results_df.iloc[0]['ROC-AUC']:.3f}\")\n",
    "print(f\"   Sensitivity: {results_df.iloc[0]['Sensitivity (Recall)']:.3f}\")\n",
    "print(f\"   Specificity: {results_df.iloc[0]['Specificity']:.3f}\")\n",
    "\n",
    "# Find model with highest sensitivity (most important for medical screening)\n",
    "best_sensitivity_idx = results_df['Sensitivity (Recall)'].idxmax()\n",
    "print(f\"\\nðŸŽ¯ Best Sensitivity Model: {results_df.loc[best_sensitivity_idx, 'Model']}\")\n",
    "print(f\"   Sensitivity: {results_df.loc[best_sensitivity_idx, 'Sensitivity (Recall)']:.3f}\")\n",
    "print(f\"   (Best at detecting heart disease - minimizes missed diagnoses)\")\n",
    "\n",
    "# Find model with highest specificity (important for avoiding false alarms)\n",
    "best_specificity_idx = results_df['Specificity'].idxmax()\n",
    "print(f\"\\nðŸ›¡ï¸  Best Specificity Model: {results_df.loc[best_specificity_idx, 'Model']}\")\n",
    "print(f\"   Specificity: {results_df.loc[best_specificity_idx, 'Specificity']:.3f}\")\n",
    "print(f\"   (Best at ruling out heart disease - minimizes false alarms)\")\n",
    "\n",
    "# Medical interpretation guidelines\n",
    "print(\"\\nðŸ¥ Clinical Interpretation Guidelines:\")\n",
    "print(\"   â€¢ Sensitivity > 0.90: Excellent for screening (few missed cases)\")\n",
    "print(\"   â€¢ Specificity > 0.80: Good for avoiding unnecessary procedures\")\n",
    "print(\"   â€¢ ROC-AUC > 0.85: Clinically acceptable discriminative ability\")\n",
    "print(\"   â€¢ CV Std < 0.05: Consistent performance across patient populations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of model performance for medical diagnosis\n",
    "print(\"ðŸ“Š Creating Comprehensive Medical Performance Visualizations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a comprehensive comparison plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Comprehensive Model Comparison for Heart Disease Diagnosis', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. ROC-AUC Comparison\n",
    "ax1 = axes[0, 0]\n",
    "sns.barplot(data=results_df, x='ROC-AUC', y='Model', palette='viridis', ax=ax1)\n",
    "ax1.set_title('ROC-AUC: Overall Discriminative Ability', fontweight='bold')\n",
    "ax1.set_xlabel('ROC-AUC Score')\n",
    "ax1.axvline(x=0.8, color='red', linestyle='--', alpha=0.7, label='Clinical Threshold')\n",
    "ax1.legend()\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(results_df['ROC-AUC']):\n",
    "    ax1.text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# 2. Sensitivity vs Specificity Trade-off\n",
    "ax2 = axes[0, 1]\n",
    "scatter = ax2.scatter(results_df['Sensitivity (Recall)'], results_df['Specificity'], \n",
    "                    s=100, alpha=0.7, c=results_df['ROC-AUC'], \n",
    "                    cmap='viridis', edgecolors='black')\n",
    "ax2.set_xlabel('Sensitivity (Recall)')\n",
    "ax2.set_ylabel('Specificity')\n",
    "ax2.set_title('Sensitivity vs Specificity Trade-off', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add model labels\n",
    "for i, model in enumerate(results_df['Model']):\n",
    "    ax2.annotate(model, (results_df['Sensitivity (Recall)'].iloc[i], \n",
    "                        results_df['Specificity'].iloc[i]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Add ideal region\n",
    "ax2.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='Specificity > 0.8')\n",
    "ax2.axvline(x=0.9, color='red', linestyle='--', alpha=0.5, label='Sensitivity > 0.9')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Cross-Validation Stability\n",
    "ax3 = axes[1, 0]\n",
    "err_bars = ax3.barh(range(len(results_df)), results_df['CV_Mean'], \n",
    "                   xerr=results_df['CV_Std'], capsize=5, alpha=0.7)\n",
    "ax3.set_yticks(range(len(results_df)))\n",
    "ax3.set_yticklabels(results_df['Model'])\n",
    "ax3.set_xlabel('Cross-Validation Accuracy')\n",
    "ax3.set_title('Model Stability (Cross-Validation)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Comprehensive Performance Radar\n",
    "ax4 = axes[1, 1]\n",
    "# Select top 3 models for radar chart\n",
    "top_models = results_df.head(3)\n",
    "metrics = ['Accuracy', 'Sensitivity (Recall)', 'Specificity', 'Precision (PPV)', 'F1-Score']\n",
    "\n",
    "# Normalize metrics to 0-1 scale for radar chart\n",
    "normalized_data = top_models[metrics].values\n",
    "\n",
    "# Simple bar chart instead of radar for clarity\n",
    "model_names = top_models['Model'].values\n",
    "x_pos = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    ax4.bar(x_pos + i*width, normalized_data[i], width, \n",
    "           label=model, alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Metrics')\n",
    "ax4.set_ylabel('Score')\n",
    "ax4.set_title('Top 3 Models: Detailed Comparison', fontweight='bold')\n",
    "ax4.set_xticks(x_pos + width)\n",
    "ax4.set_xticklabels(metrics, rotation=45)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional summary statistics\n",
    "print(\"\\nðŸ“ˆ Performance Summary Statistics:\")\n",
    "print(f\"   Mean ROC-AUC across all models: {results_df['ROC-AUC'].mean():.3f}\")\n",
    "print(f\"   Best ROC-AUC: {results_df['ROC-AUC'].max():.3f}\")\n",
    "print(f\"   Mean Sensitivity: {results_df['Sensitivity (Recall)'].mean():.3f}\")\n",
    "print(f\"   Mean Specificity: {results_df['Specificity'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we compared the performance of SVM with other models on both heart disease diagnosis and news classification tasks. The results indicate that SVM can be competitive with other models, depending on the dataset and the chosen hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
