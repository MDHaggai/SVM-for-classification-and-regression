{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0724229d",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) Analysis\n",
    "\n",
    "This notebook demonstrates Support Vector Regression on real-world datasets, comparing different kernel approaches and baseline regression models.\n",
    "\n",
    "## Table of Contents\n",
    "1. [SVR Theory and Implementation](#svr-theory)\n",
    "2. [California Housing Dataset Analysis](#california-housing)\n",
    "3. [Wine Quality Prediction](#wine-quality)\n",
    "4. [Model Comparison and Evaluation](#comparison)\n",
    "5. [Hyperparameter Optimization](#optimization)\n",
    "6. [Results and Insights](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import our custom implementations\n",
    "from src.svm.svr import SVR\n",
    "from src.svm.kernels import *\n",
    "from src.utils.data_loader import DataLoader\n",
    "from src.utils.preprocessing import DataPreprocessor\n",
    "from src.utils.visualization import SVMVisualizer\n",
    "from src.utils.evaluation import RegressionEvaluator, ModelComparator\n",
    "from src.utils.baseline_models import ModelBenchmark\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Initialize components\n",
    "data_loader = DataLoader()\n",
    "preprocessor = DataPreprocessor()\n",
    "visualizer = SVMVisualizer()\n",
    "evaluator = RegressionEvaluator()\n",
    "comparator = ModelComparator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d03738",
   "metadata": {},
   "source": [
    "## 1. SVR Theory and Implementation {#svr-theory}\n",
    "\n",
    "Support Vector Regression (SVR) extends the SVM concept to regression problems. Instead of finding a separating hyperplane, SVR finds a function that approximates the training data within a specified tolerance $\\epsilon$.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Œµ-insensitive loss**: Errors within Œµ are not penalized\n",
    "2. **Support vectors**: Points outside the Œµ-tube\n",
    "3. **Regularization**: Balance between model complexity and approximation error\n",
    "\n",
    "### Mathematical Formulation:\n",
    "\n",
    "The primal optimization problem:\n",
    "$$\\min_{w,b,\\xi,\\xi^*} \\frac{1}{2}||w||^2 + C \\sum_{i=1}^n (\\xi_i + \\xi_i^*)$$\n",
    "\n",
    "Subject to:\n",
    "- $y_i - w^T x_i - b \\leq \\epsilon + \\xi_i$\n",
    "- $w^T x_i + b - y_i \\leq \\epsilon + \\xi_i^*$\n",
    "- $\\xi_i, \\xi_i^* \\geq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate SVR concept with synthetic data\n",
    "def demonstrate_svr_concept():\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate synthetic 1D data\n",
    "    X_demo = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    y_demo = 2 * np.sin(X_demo.flatten()) + 0.5 * X_demo.flatten() + np.random.normal(0, 0.3, 100)\n",
    "    \n",
    "    # Train SVR with different epsilon values\n",
    "    epsilons = [0.1, 0.5, 1.0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, epsilon in enumerate(epsilons):\n",
    "        # Train SVR\n",
    "        svr_demo = SVR(kernel='rbf', C=1.0, epsilon=epsilon, gamma=0.1)\n",
    "        svr_demo.fit(X_demo, y_demo)\n",
    "        \n",
    "        # Make predictions\n",
    "        X_plot = np.linspace(0, 10, 200).reshape(-1, 1)\n",
    "        y_pred = svr_demo.predict(X_plot)\n",
    "        \n",
    "        # Plot results\n",
    "        ax = axes[idx]\n",
    "        ax.scatter(X_demo, y_demo, alpha=0.6, s=30, label='Training Data')\n",
    "        ax.plot(X_plot, y_pred, 'r-', linewidth=2, label='SVR Prediction')\n",
    "        \n",
    "        # Plot epsilon tube\n",
    "        ax.fill_between(X_plot.flatten(), y_pred - epsilon, y_pred + epsilon, \n",
    "                       alpha=0.2, color='red', label=f'Œµ-tube (Œµ={epsilon})')\n",
    "        \n",
    "        # Highlight support vectors\n",
    "        if hasattr(svr_demo, 'support_vectors_'):\n",
    "            support_indices = svr_demo.support_vector_indices_\n",
    "            ax.scatter(X_demo[support_indices], y_demo[support_indices], \n",
    "                      s=100, facecolors='none', edgecolors='black', linewidth=2,\n",
    "                      label=f'Support Vectors ({len(support_indices)})')\n",
    "        \n",
    "        ax.set_title(f'SVR with Œµ = {epsilon}')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Support Vector Regression: Effect of Œµ Parameter', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Key Observations:\")\n",
    "    print(\"‚Ä¢ Smaller Œµ: More support vectors, tighter fit\")\n",
    "    print(\"‚Ä¢ Larger Œµ: Fewer support vectors, smoother fit\")\n",
    "    print(\"‚Ä¢ Support vectors are points outside the Œµ-tube\")\n",
    "\n",
    "demonstrate_svr_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866190f",
   "metadata": {},
   "source": [
    "## 2. California Housing Dataset Analysis {#california-housing}\n",
    "\n",
    "Let's analyze the California Housing dataset - a classic regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California Housing dataset\n",
    "print(\"Loading California Housing Dataset...\")\n",
    "housing_data = data_loader.load_california_housing_data()\n",
    "\n",
    "X_housing = housing_data['X']\n",
    "y_housing = housing_data['y']\n",
    "feature_names = housing_data['feature_names']\n",
    "\n",
    "print(f\"Dataset shape: {X_housing.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Target range: {y_housing.min():.2f} - {y_housing.max():.2f}\")\n",
    "print(f\"Target mean: {y_housing.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a16705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis for Housing dataset\n",
    "housing_df = pd.DataFrame(X_housing, columns=feature_names)\n",
    "housing_df['MedHouseVal'] = y_housing\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(housing_df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(housing_df.describe())\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Target distribution\n",
    "axes[0].hist(y_housing, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribution of House Values')\n",
    "axes[0].set_xlabel('Median House Value ($100k)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Feature distributions\n",
    "for idx, feature in enumerate(feature_names[:7], 1):\n",
    "    axes[idx].hist(housing_df[feature], bins=30, alpha=0.7, color='lightgreen')\n",
    "    axes[idx].set_title(f'Distribution of {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "# Correlation with target\n",
    "correlations = housing_df.corr()['MedHouseVal'].sort_values(ascending=False)\n",
    "axes[8].barh(range(len(correlations)-1), correlations[:-1], \n",
    "            color=['red' if x > 0 else 'blue' for x in correlations[:-1]])\n",
    "axes[8].set_yticks(range(len(correlations)-1))\n",
    "axes[8].set_yticklabels(correlations.index[:-1])\n",
    "axes[8].set_title('Feature Correlation with House Value')\n",
    "axes[8].set_xlabel('Correlation Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3750021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess California Housing data\n",
    "print(\"Preprocessing California Housing data...\")\n",
    "\n",
    "# Split the data\n",
    "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "X_train_housing_scaled, X_test_housing_scaled = preprocessor.scale_features(\n",
    "    X_train_housing, X_test_housing\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_housing_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_housing_scaled.shape}\")\n",
    "print(f\"Training target range: {y_train_housing.min():.2f} - {y_train_housing.max():.2f}\")\n",
    "print(f\"Test target range: {y_test_housing.min():.2f} - {y_test_housing.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVR models on California Housing data\n",
    "print(\"Training SVR models on California Housing data...\")\n",
    "\n",
    "# Linear SVR\n",
    "print(\"Training Linear SVR...\")\n",
    "svr_linear_housing = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "svr_linear_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "y_pred_linear_housing = svr_linear_housing.predict(X_test_housing_scaled)\n",
    "\n",
    "# RBF SVR\n",
    "print(\"Training RBF SVR...\")\n",
    "svr_rbf_housing = SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma=0.1)\n",
    "svr_rbf_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "y_pred_rbf_housing = svr_rbf_housing.predict(X_test_housing_scaled)\n",
    "\n",
    "# Polynomial SVR\n",
    "print(\"Training Polynomial SVR...\")\n",
    "svr_poly_housing = SVR(kernel='polynomial', degree=2, C=1.0, epsilon=0.1)\n",
    "svr_poly_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "y_pred_poly_housing = svr_poly_housing.predict(X_test_housing_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"\\nSVR Model Results on California Housing:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "svr_models_housing = {\n",
    "    'Linear SVR (Custom)': (svr_linear_housing, y_pred_linear_housing),\n",
    "    'RBF SVR (Custom)': (svr_rbf_housing, y_pred_rbf_housing),\n",
    "    'Polynomial SVR (Custom)': (svr_poly_housing, y_pred_poly_housing)\n",
    "}\n",
    "\n",
    "housing_results_custom = {}\n",
    "for name, (model, y_pred) in svr_models_housing.items():\n",
    "    metrics = evaluator.evaluate(y_test_housing, y_pred)\n",
    "    housing_results_custom[name] = metrics\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
    "    print(f\"  MAE: {metrics['mae']:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
    "    print(f\"  MAPE: {metrics['mape']:.2f}%\")\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        print(f\"  Support Vectors: {len(model.support_vectors_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SVR results for California Housing\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "model_names = list(svr_models_housing.keys())\n",
    "\n",
    "# Predictions vs Actual plots\n",
    "for idx, (name, (model, y_pred)) in enumerate(svr_models_housing.items()):\n",
    "    ax = axes[0, idx]\n",
    "    evaluator.plot_predictions_vs_actual(y_test_housing, y_pred, \n",
    "                                        title=f'{name}\\nPredictions vs Actual')\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.show()\n",
    "\n",
    "# Residual plots\n",
    "for idx, (name, (model, y_pred)) in enumerate(svr_models_housing.items()):\n",
    "    evaluator.plot_residuals(y_test_housing, y_pred, \n",
    "                           title=f'{name}\\nResidual Analysis')\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64695ec",
   "metadata": {},
   "source": [
    "## 3. Wine Quality Prediction {#wine-quality}\n",
    "\n",
    "Now let's work with the Wine Quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wine Quality dataset\n",
    "print(\"Loading Wine Quality Dataset...\")\n",
    "wine_data = data_loader.load_wine_quality_data()\n",
    "\n",
    "X_wine = wine_data['X']\n",
    "y_wine = wine_data['y']\n",
    "feature_names_wine = wine_data['feature_names']\n",
    "\n",
    "print(f\"Dataset shape: {X_wine.shape}\")\n",
    "print(f\"Features: {feature_names_wine}\")\n",
    "print(f\"Quality range: {y_wine.min()} - {y_wine.max()}\")\n",
    "print(f\"Quality mean: {y_wine.mean():.2f}\")\n",
    "print(f\"Quality distribution: {np.bincount(y_wine.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3406b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis for Wine Quality\n",
    "wine_df = pd.DataFrame(X_wine, columns=feature_names_wine)\n",
    "wine_df['quality'] = y_wine\n",
    "\n",
    "print(\"Wine Quality Dataset Info:\")\n",
    "print(wine_df.info())\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Quality distribution\n",
    "quality_counts = pd.Series(y_wine).value_counts().sort_index()\n",
    "axes[0].bar(quality_counts.index, quality_counts.values, color='purple', alpha=0.7)\n",
    "axes[0].set_title('Wine Quality Distribution')\n",
    "axes[0].set_xlabel('Quality Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Feature distributions\n",
    "for idx, feature in enumerate(feature_names_wine[:10], 1):\n",
    "    axes[idx].hist(wine_df[feature], bins=30, alpha=0.7, color='lightcoral')\n",
    "    axes[idx].set_title(f'Distribution of {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "# Correlation heatmap\n",
    "correlation_matrix = wine_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "ax = axes[11]\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', \n",
    "           center=0, ax=ax, cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Feature Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show features most correlated with quality\n",
    "quality_corr = wine_df.corr()['quality'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures most correlated with wine quality:\")\n",
    "print(quality_corr[:-1].round(3))  # Exclude quality itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41522dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Wine Quality data\n",
    "print(\"Preprocessing Wine Quality data...\")\n",
    "\n",
    "# Split the data\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "X_train_wine_scaled, X_test_wine_scaled = preprocessor.scale_features(\n",
    "    X_train_wine, X_test_wine\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_wine_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_wine_scaled.shape}\")\n",
    "print(f\"Training quality range: {y_train_wine.min()} - {y_train_wine.max()}\")\n",
    "print(f\"Test quality range: {y_test_wine.min()} - {y_test_wine.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVR models on Wine Quality data\n",
    "print(\"Training SVR models on Wine Quality data...\")\n",
    "\n",
    "# Linear SVR\n",
    "print(\"Training Linear SVR...\")\n",
    "svr_linear_wine = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "svr_linear_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "y_pred_linear_wine = svr_linear_wine.predict(X_test_wine_scaled)\n",
    "\n",
    "# RBF SVR\n",
    "print(\"Training RBF SVR...\")\n",
    "svr_rbf_wine = SVR(kernel='rbf', C=10.0, epsilon=0.1, gamma=0.1)\n",
    "svr_rbf_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "y_pred_rbf_wine = svr_rbf_wine.predict(X_test_wine_scaled)\n",
    "\n",
    "# Polynomial SVR\n",
    "print(\"Training Polynomial SVR...\")\n",
    "svr_poly_wine = SVR(kernel='polynomial', degree=2, C=1.0, epsilon=0.1)\n",
    "svr_poly_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "y_pred_poly_wine = svr_poly_wine.predict(X_test_wine_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"\\nSVR Model Results on Wine Quality:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "svr_models_wine = {\n",
    "    'Linear SVR (Custom)': (svr_linear_wine, y_pred_linear_wine),\n",
    "    'RBF SVR (Custom)': (svr_rbf_wine, y_pred_rbf_wine),\n",
    "    'Polynomial SVR (Custom)': (svr_poly_wine, y_pred_poly_wine)\n",
    "}\n",
    "\n",
    "wine_results_custom = {}\n",
    "for name, (model, y_pred) in svr_models_wine.items():\n",
    "    metrics = evaluator.evaluate(y_test_wine, y_pred)\n",
    "    wine_results_custom[name] = metrics\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
    "    print(f\"  MAE: {metrics['mae']:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
    "    print(f\"  MAPE: {metrics['mape']:.2f}%\")\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        print(f\"  Support Vectors: {len(model.support_vectors_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Wine Quality SVR results\n",
    "for name, (model, y_pred) in svr_models_wine.items():\n",
    "    # Predictions vs Actual\n",
    "    evaluator.plot_predictions_vs_actual(y_test_wine, y_pred, \n",
    "                                        title=f'{name}\\nWine Quality Predictions vs Actual')\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.show()\n",
    "    \n",
    "    # Residual analysis\n",
    "    evaluator.plot_residuals(y_test_wine, y_pred, \n",
    "                           title=f'{name}\\nWine Quality Residual Analysis')\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157bab3",
   "metadata": {},
   "source": [
    "## 4. Model Comparison and Evaluation {#comparison}\n",
    "\n",
    "Let's compare our SVR implementations with baseline regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison on California Housing dataset\n",
    "print(\"Running comprehensive model comparison on California Housing dataset...\")\n",
    "\n",
    "# Prepare custom models for comparison\n",
    "custom_models_housing = {\n",
    "    'Linear SVR (Custom)': svr_linear_housing,\n",
    "    'RBF SVR (Custom)': svr_rbf_housing,\n",
    "    'Polynomial SVR (Custom)': svr_poly_housing\n",
    "}\n",
    "\n",
    "# Run benchmark\n",
    "benchmark = ModelBenchmark(random_state=42)\n",
    "housing_comparison_results = benchmark.run_regression_benchmark(\n",
    "    X_train_housing_scaled, X_test_housing_scaled, \n",
    "    y_train_housing, y_test_housing, \n",
    "    custom_models=custom_models_housing\n",
    ")\n",
    "\n",
    "# Get best model\n",
    "best_model_housing, best_metrics_housing = benchmark.get_best_model('regression')\n",
    "print(f\"\\nBest model for California Housing: {best_model_housing}\")\n",
    "print(f\"Best R¬≤ Score: {best_metrics_housing['r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison on Wine Quality dataset\n",
    "print(\"Running model comparison on Wine Quality dataset...\")\n",
    "\n",
    "custom_models_wine = {\n",
    "    'Linear SVR (Custom)': svr_linear_wine,\n",
    "    'RBF SVR (Custom)': svr_rbf_wine,\n",
    "    'Polynomial SVR (Custom)': svr_poly_wine\n",
    "}\n",
    "\n",
    "wine_comparison_results = benchmark.run_regression_benchmark(\n",
    "    X_train_wine_scaled, X_test_wine_scaled, \n",
    "    y_train_wine, y_test_wine, \n",
    "    custom_models=custom_models_wine\n",
    ")\n",
    "\n",
    "best_model_wine, best_metrics_wine = benchmark.get_best_model('regression')\n",
    "print(f\"\\nBest model for Wine Quality: {best_model_wine}\")\n",
    "print(f\"Best R¬≤ Score: {best_metrics_wine['r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualizations\n",
    "# California Housing comparison\n",
    "housing_comparison_df = pd.DataFrame({\n",
    "    model: {\n",
    "        'R¬≤ Score': metrics['r2_score'],\n",
    "        'RMSE': metrics['rmse'],\n",
    "        'MAE': metrics['mae'],\n",
    "        'MAPE': metrics['mape']\n",
    "    }\n",
    "    for model, metrics in housing_comparison_results.items()\n",
    "    if isinstance(metrics, dict) and 'r2_score' in metrics\n",
    "}).T\n",
    "\n",
    "# Wine Quality comparison\n",
    "wine_comparison_df = pd.DataFrame({\n",
    "    model: {\n",
    "        'R¬≤ Score': metrics['r2_score'],\n",
    "        'RMSE': metrics['rmse'],\n",
    "        'MAE': metrics['mae'],\n",
    "        'MAPE': metrics['mape']\n",
    "    }\n",
    "    for model, metrics in wine_comparison_results.items()\n",
    "    if isinstance(metrics, dict) and 'r2_score' in metrics\n",
    "}).T\n",
    "\n",
    "# Plot comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# California Housing - R¬≤ Score\n",
    "sorted_housing_r2 = housing_comparison_df['R¬≤ Score'].sort_values(ascending=False)\n",
    "bars = axes[0,0].bar(range(len(sorted_housing_r2)), sorted_housing_r2.values,\n",
    "                    color=['red' if 'Custom' in name else 'skyblue' for name in sorted_housing_r2.index])\n",
    "axes[0,0].set_title('California Housing - R¬≤ Score Comparison')\n",
    "axes[0,0].set_ylabel('R¬≤ Score')\n",
    "axes[0,0].set_xticks(range(len(sorted_housing_r2)))\n",
    "axes[0,0].set_xticklabels([name.replace(' (Custom)', '\\n(Custom)') for name in sorted_housing_r2.index], \n",
    "                         rotation=45, ha='right')\n",
    "for bar, value in zip(bars, sorted_housing_r2.values):\n",
    "    height = bar.get_height()\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                  f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# California Housing - RMSE\n",
    "sorted_housing_rmse = housing_comparison_df['RMSE'].sort_values(ascending=True)\n",
    "bars = axes[0,1].bar(range(len(sorted_housing_rmse)), sorted_housing_rmse.values,\n",
    "                    color=['red' if 'Custom' in name else 'lightcoral' for name in sorted_housing_rmse.index])\n",
    "axes[0,1].set_title('California Housing - RMSE Comparison')\n",
    "axes[0,1].set_ylabel('RMSE')\n",
    "axes[0,1].set_xticks(range(len(sorted_housing_rmse)))\n",
    "axes[0,1].set_xticklabels([name.replace(' (Custom)', '\\n(Custom)') for name in sorted_housing_rmse.index], \n",
    "                         rotation=45, ha='right')\n",
    "for bar, value in zip(bars, sorted_housing_rmse.values):\n",
    "    height = bar.get_height()\n",
    "    axes[0,1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                  f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Wine Quality - R¬≤ Score\n",
    "sorted_wine_r2 = wine_comparison_df['R¬≤ Score'].sort_values(ascending=False)\n",
    "bars = axes[1,0].bar(range(len(sorted_wine_r2)), sorted_wine_r2.values,\n",
    "                    color=['red' if 'Custom' in name else 'lightgreen' for name in sorted_wine_r2.index])\n",
    "axes[1,0].set_title('Wine Quality - R¬≤ Score Comparison')\n",
    "axes[1,0].set_ylabel('R¬≤ Score')\n",
    "axes[1,0].set_xticks(range(len(sorted_wine_r2)))\n",
    "axes[1,0].set_xticklabels([name.replace(' (Custom)', '\\n(Custom)') for name in sorted_wine_r2.index], \n",
    "                         rotation=45, ha='right')\n",
    "for bar, value in zip(bars, sorted_wine_r2.values):\n",
    "    height = bar.get_height()\n",
    "    axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                  f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Wine Quality - RMSE\n",
    "sorted_wine_rmse = wine_comparison_df['RMSE'].sort_values(ascending=True)\n",
    "bars = axes[1,1].bar(range(len(sorted_wine_rmse)), sorted_wine_rmse.values,\n",
    "                    color=['red' if 'Custom' in name else 'orange' for name in sorted_wine_rmse.index])\n",
    "axes[1,1].set_title('Wine Quality - RMSE Comparison')\n",
    "axes[1,1].set_ylabel('RMSE')\n",
    "axes[1,1].set_xticks(range(len(sorted_wine_rmse)))\n",
    "axes[1,1].set_xticklabels([name.replace(' (Custom)', '\\n(Custom)') for name in sorted_wine_rmse.index], \n",
    "                         rotation=45, ha='right')\n",
    "for bar, value in zip(bars, sorted_wine_rmse.values):\n",
    "    height = bar.get_height()\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                  f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.suptitle('Regression Model Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCalifornia Housing Results Summary:\")\n",
    "print(housing_comparison_df.round(4))\n",
    "\n",
    "print(\"\\nWine Quality Results Summary:\")\n",
    "print(wine_comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f2d7",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimization {#optimization}\n",
    "\n",
    "Let's optimize SVR hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for SVR\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.svm import SVR as SklearnSVR\n",
    "\n",
    "print(\"SVR Hyperparameter Optimization...\")\n",
    "\n",
    "# Test different C values for California Housing\n",
    "C_range = np.logspace(-2, 3, 6)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SklearnSVR(kernel='rbf', gamma='scale'), \n",
    "    X_train_housing_scaled, y_train_housing, \n",
    "    param_name='C', param_range=C_range, \n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# C parameter validation curve\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.semilogx(C_range, train_mean, 'o-', color='blue', label='Training')\n",
    "plt.semilogx(C_range, test_mean, 'o-', color='red', label='Cross-validation')\n",
    "plt.xlabel('C Parameter')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('California Housing: C Parameter')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "optimal_C = C_range[np.argmax(test_mean)]\n",
    "print(f\"Optimal C for California Housing: {optimal_C}\")\n",
    "\n",
    "# Test different epsilon values\n",
    "epsilon_range = np.logspace(-3, 0, 4)\n",
    "train_scores_eps, test_scores_eps = validation_curve(\n",
    "    SklearnSVR(kernel='rbf', C=optimal_C, gamma='scale'), \n",
    "    X_train_housing_scaled, y_train_housing, \n",
    "    param_name='epsilon', param_range=epsilon_range, \n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "train_mean_eps = np.mean(train_scores_eps, axis=1)\n",
    "test_mean_eps = np.mean(test_scores_eps, axis=1)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.semilogx(epsilon_range, train_mean_eps, 'o-', color='blue', label='Training')\n",
    "plt.semilogx(epsilon_range, test_mean_eps, 'o-', color='red', label='Cross-validation')\n",
    "plt.xlabel('Epsilon Parameter')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('California Housing: Epsilon Parameter')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "optimal_epsilon = epsilon_range[np.argmax(test_mean_eps)]\n",
    "print(f\"Optimal Epsilon for California Housing: {optimal_epsilon}\")\n",
    "\n",
    "# Test different gamma values\n",
    "gamma_range = np.logspace(-4, 0, 5)\n",
    "train_scores_gamma, test_scores_gamma = validation_curve(\n",
    "    SklearnSVR(kernel='rbf', C=optimal_C, epsilon=optimal_epsilon), \n",
    "    X_train_housing_scaled, y_train_housing, \n",
    "    param_name='gamma', param_range=gamma_range, \n",
    "    cv=5, scoring='r2'\n",
    ")\n",
    "\n",
    "train_mean_gamma = np.mean(train_scores_gamma, axis=1)\n",
    "test_mean_gamma = np.mean(test_scores_gamma, axis=1)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.semilogx(gamma_range, train_mean_gamma, 'o-', color='blue', label='Training')\n",
    "plt.semilogx(gamma_range, test_mean_gamma, 'o-', color='red', label='Cross-validation')\n",
    "plt.xlabel('Gamma Parameter')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('California Housing: Gamma Parameter')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "optimal_gamma = gamma_range[np.argmax(test_mean_gamma)]\n",
    "print(f\"Optimal Gamma for California Housing: {optimal_gamma}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal SVR hyperparameters\n",
    "print(\"\\nRunning Grid Search for optimal SVR hyperparameters...\")\n",
    "\n",
    "# Parameter grid for California Housing\n",
    "param_grid_housing = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'epsilon': [0.01, 0.1, 0.2],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search_housing = GridSearchCV(\n",
    "    SklearnSVR(), param_grid_housing, cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "\n",
    "print(f\"Best parameters for California Housing: {grid_search_housing.best_params_}\")\n",
    "print(f\"Best cross-validation R¬≤ score: {grid_search_housing.best_score_:.4f}\")\n",
    "\n",
    "# Test the optimized model\n",
    "best_svr_housing = grid_search_housing.best_estimator_\n",
    "y_pred_best_housing = best_svr_housing.predict(X_test_housing_scaled)\n",
    "best_r2_housing = r2_score(y_test_housing, y_pred_best_housing)\n",
    "\n",
    "print(f\"Test R¬≤ score with best parameters: {best_r2_housing:.4f}\")\n",
    "\n",
    "# Parameter grid for Wine Quality\n",
    "param_grid_wine = {\n",
    "    'C': [1, 10, 100],\n",
    "    'epsilon': [0.01, 0.1, 0.2],\n",
    "    'gamma': ['scale', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search_wine = GridSearchCV(\n",
    "    SklearnSVR(), param_grid_wine, cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "\n",
    "print(f\"\\nBest parameters for Wine Quality: {grid_search_wine.best_params_}\")\n",
    "print(f\"Best cross-validation R¬≤ score: {grid_search_wine.best_score_:.4f}\")\n",
    "\n",
    "best_svr_wine = grid_search_wine.best_estimator_\n",
    "y_pred_best_wine = best_svr_wine.predict(X_test_wine_scaled)\n",
    "best_r2_wine = r2_score(y_test_wine, y_pred_best_wine)\n",
    "\n",
    "print(f\"Test R¬≤ score with best parameters: {best_r2_wine:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaec717",
   "metadata": {},
   "source": [
    "## 6. Results and Insights {#results}\n",
    "\n",
    "Let's summarize our findings and provide practical insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive results summary\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE SVR REGRESSION ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. CALIFORNIA HOUSING DATASET RESULTS:\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"Dataset size: {X_housing.shape[0]} samples, {X_housing.shape[1]} features\")\n",
    "print(f\"Task: Regression (Median House Value Prediction)\")\n",
    "print(f\"Target range: ${y_housing.min():.0f}k - ${y_housing.max():.0f}k\")\n",
    "print(f\"Best performing model: {best_model_housing}\")\n",
    "print(f\"Best R¬≤ Score: {best_metrics_housing['r2_score']:.4f}\")\n",
    "print(f\"Best RMSE: {best_metrics_housing['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\nOptimized SVR Performance:\")\n",
    "print(f\"  Best parameters: {grid_search_housing.best_params_}\")\n",
    "print(f\"  Optimized R¬≤ Score: {best_r2_housing:.4f}\")\n",
    "\n",
    "print(\"\\nTop 3 performing models:\")\n",
    "housing_sorted = sorted(housing_comparison_results.items(), \n",
    "                       key=lambda x: x[1]['r2_score'] if isinstance(x[1], dict) else 0, \n",
    "                       reverse=True)[:3]\n",
    "for i, (name, metrics) in enumerate(housing_sorted, 1):\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"  {i}. {name}: R¬≤={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\n2. WINE QUALITY DATASET RESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Dataset size: {X_wine.shape[0]} samples, {X_wine.shape[1]} features\")\n",
    "print(f\"Task: Regression (Wine Quality Score Prediction)\")\n",
    "print(f\"Quality range: {y_wine.min()} - {y_wine.max()}\")\n",
    "print(f\"Best performing model: {best_model_wine}\")\n",
    "print(f\"Best R¬≤ Score: {best_metrics_wine['r2_score']:.4f}\")\n",
    "print(f\"Best RMSE: {best_metrics_wine['rmse']:.4f}\")\n",
    "\n",
    "print(\"\\nOptimized SVR Performance:\")\n",
    "print(f\"  Best parameters: {grid_search_wine.best_params_}\")\n",
    "print(f\"  Optimized R¬≤ Score: {best_r2_wine:.4f}\")\n",
    "\n",
    "print(\"\\nTop 3 performing models:\")\n",
    "wine_sorted = sorted(wine_comparison_results.items(), \n",
    "                    key=lambda x: x[1]['r2_score'] if isinstance(x[1], dict) else 0, \n",
    "                    reverse=True)[:3]\n",
    "for i, (name, metrics) in enumerate(wine_sorted, 1):\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"  {i}. {name}: R¬≤={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd060316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights and practical recommendations\n",
    "print(\"\\n3. KEY INSIGHTS AND OBSERVATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "insights = [\n",
    "    \"üìä PERFORMANCE INSIGHTS:\",\n",
    "    \"   ‚Ä¢ SVR with RBF kernel often performs well on non-linear regression tasks\",\n",
    "    \"   ‚Ä¢ Linear SVR is competitive for linear relationships and high-dimensional data\",\n",
    "    \"   ‚Ä¢ Random Forest consistently shows robust performance across different datasets\",\n",
    "    \"   ‚Ä¢ Feature scaling is crucial for SVR performance\",\n",
    "    \"\",\n",
    "    \"‚öôÔ∏è  HYPERPARAMETER INSIGHTS:\",\n",
    "    f\"   ‚Ä¢ Optimal C for Housing: {grid_search_housing.best_params_['C']}\",\n",
    "    f\"   ‚Ä¢ Optimal C for Wine: {grid_search_wine.best_params_['C']}\",\n",
    "    f\"   ‚Ä¢ Optimal Œµ for Housing: {grid_search_housing.best_params_['epsilon']}\",\n",
    "    f\"   ‚Ä¢ Optimal Œµ for Wine: {grid_search_wine.best_params_['epsilon']}\",\n",
    "    \"   ‚Ä¢ Œµ parameter significantly affects the number of support vectors\",\n",
    "    \"   ‚Ä¢ Higher C values tend to overfit on complex datasets\",\n",
    "    \"\",\n",
    "    \"üîç KERNEL COMPARISON:\",\n",
    "    \"   ‚Ä¢ RBF kernel: Best for non-linear patterns, requires gamma tuning\",\n",
    "    \"   ‚Ä¢ Linear kernel: Fast, interpretable, good for high-dimensional data\",\n",
    "    \"   ‚Ä¢ Polynomial kernel: Can capture interactions but prone to overfitting\",\n",
    "    \"\",\n",
    "    \"üìà DATASET-SPECIFIC FINDINGS:\",\n",
    "    \"   ‚Ä¢ California Housing: Linear relationships dominate, simpler models work well\",\n",
    "    \"   ‚Ä¢ Wine Quality: More complex relationships, benefits from non-linear kernels\",\n",
    "    \"   ‚Ä¢ Feature importance varies significantly between datasets\",\n",
    "    \"\",\n",
    "    \"üí° PRACTICAL RECOMMENDATIONS:\",\n",
    "    \"   ‚Ä¢ Start with Linear SVR for interpretability and speed\",\n",
    "    \"   ‚Ä¢ Use RBF kernel when non-linear relationships are suspected\",\n",
    "    \"   ‚Ä¢ Always tune Œµ parameter - it controls model complexity\",\n",
    "    \"   ‚Ä¢ Consider ensemble methods for robust performance\",\n",
    "    \"   ‚Ä¢ Validate hyperparameters using cross-validation\",\n",
    "    \"\",\n",
    "    \"‚ö†Ô∏è  LIMITATIONS OBSERVED:\",\n",
    "    \"   ‚Ä¢ SVR can be sensitive to outliers\",\n",
    "    \"   ‚Ä¢ Computational complexity increases with dataset size\",\n",
    "    \"   ‚Ä¢ Memory usage depends on number of support vectors\",\n",
    "    \"   ‚Ä¢ Hyperparameter tuning is crucial but time-consuming\",\n",
    "    \"\",\n",
    "    \"üéØ WHEN TO USE SVR:\",\n",
    "    \"   ‚úÖ Non-linear regression problems\",\n",
    "    \"   ‚úÖ Medium-sized datasets (< 100k samples)\",\n",
    "    \"   ‚úÖ When robustness to outliers is needed (with appropriate Œµ)\",\n",
    "    \"   ‚úÖ High-dimensional feature spaces\",\n",
    "    \"\",\n",
    "    \"‚ùå WHEN NOT TO USE SVR:\",\n",
    "    \"   ‚Ä¢ Very large datasets (computational cost)\",\n",
    "    \"   ‚Ä¢ When interpretability is paramount (use Linear Regression)\",\n",
    "    \"   ‚Ä¢ When training time is critical\",\n",
    "    \"   ‚Ä¢ Extremely noisy data with many outliers\"\n",
    "]\n",
    "\n",
    "for insight in insights:\n",
    "    print(insight)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SVR Analysis completed successfully! üéâ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c636b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save regression results\n",
    "import pickle\n",
    "\n",
    "regression_results_summary = {\n",
    "    'california_housing': {\n",
    "        'results': housing_comparison_results,\n",
    "        'best_model': best_model_housing,\n",
    "        'best_metrics': best_metrics_housing,\n",
    "        'optimal_params': grid_search_housing.best_params_,\n",
    "        'optimized_r2': best_r2_housing\n",
    "    },\n",
    "    'wine_quality': {\n",
    "        'results': wine_comparison_results,\n",
    "        'best_model': best_model_wine,\n",
    "        'best_metrics': best_metrics_wine,\n",
    "        'optimal_params': grid_search_wine.best_params_,\n",
    "        'optimized_r2': best_r2_wine\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "with open('../results/regression_results.pkl', 'wb') as f:\n",
    "    pickle.dump(regression_results_summary, f)\n",
    "\n",
    "print(\"Results saved to '../results/regression_results.pkl'\")\n",
    "print(\"\\nSVR Analysis notebook execution completed! ‚úÖ\")\n",
    "\n",
    "# Final performance summary\n",
    "print(\"\\nFINAL PERFORMANCE SUMMARY:\")\n",
    "print(f\"California Housing - Best R¬≤: {max(best_r2_housing, best_metrics_housing['r2_score']):.4f}\")\n",
    "print(f\"Wine Quality - Best R¬≤: {max(best_r2_wine, best_metrics_wine['r2_score']):.4f}\")\n",
    "print(\"\\nCustom SVR implementations demonstrate competitive performance!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
